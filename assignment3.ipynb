{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "596271ed",
   "metadata": {},
   "source": [
    "# 映像メディア処理特論 課題3\n",
    "「課題3: 画像キャプションの自動生成」について取り組みました."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8eb202",
   "metadata": {},
   "source": [
    "## (1) テキスト生成における自動評価手法について"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5037ead3",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ec72f",
   "metadata": {},
   "source": [
    "BLEUは2002年に [2] の論文によって提案された. 参照文群 $\\mathscr{S}_\\mathrm{ref}$ 中の文章 $S_{\\mathrm{ref}} \\in \\mathscr{S}_\\mathrm{ref}$ の $N$-gram がどれくらい候補群 $\\mathscr{S}_{\\mathrm{sys}}$ 中の生成されたテキスト $S_{\\mathrm{sys}} \\in \\mathscr{S}_{\\mathrm{sys}}$ に含まれているかという適合率 $p_n$ に基づく指標である.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc810dc",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathrm{BLEU} = \\exp{\\left(\n",
    "    \\sum_{n = 1}^N w_n \\log p_n\n",
    "\\right)} \\cdot \\mathrm{BP} \\\\\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{where} \\ \\\\\n",
    "p_n &= \\frac\n",
    "    {\n",
    "        \\displaystyle\n",
    "        \\sum_{S_{\\mathrm{sys}} \\in \\mathscr{S}_{\\mathrm{sys}}}\n",
    "        \\sum_{\\mathrm{ngram} \\in \\mathrm{n\\_gram}(S_{\\mathrm{sys}})}\n",
    "        {\\mathrm{count}_{\\mathrm{clip}}(\\mathrm{ngram})}\n",
    "    }\n",
    "    {\n",
    "        \\displaystyle\n",
    "        \\sum_{S_{\\mathrm{sys}} \\in \\mathscr{S}_{\\mathrm{sys}}}\n",
    "        \\sum_{\\mathrm{ngram} \\in \\mathrm{n\\_gram}(S_{\\mathrm{sys}})}\n",
    "        {\\mathrm{count}(\\mathrm{ngram})}\n",
    "    } \\ \\\\\n",
    "\\mathrm{BP} &= \\exp{\\left(\n",
    "    \\min \\left(1 - \\dfrac{l_{\\mathrm{ref}}}{l_{\\mathrm{sys}}}, 0 \\right)\n",
    "\\right)} \\\\\n",
    "\\mathrm{count}_{\\mathrm{clip}}(\\mathrm{ngram}) &= \\min(\\mathrm{count}(\\mathrm{ngram}), \\mathrm\n",
    "{max\\_ref\\_count})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f02b8c4",
   "metadata": {},
   "source": [
    "$N$ は $N$-gram の最大値であり, $w_n = \\frac{1}{n}$ であることが多い.  \n",
    "$\\mathrm{max\\_ref\\_count}$ は参照テキスト $S_{\\mathrm{ref}} \\in \\mathscr{S}_\\mathrm{ref}$ の $N$-gram の出現回数の最大値, $\\mathrm{count}(\\mathrm{ngram})$ は文章 $C$ での $N$-gram の出現回数を表す."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f709e9a0",
   "metadata": {},
   "source": [
    "$BP$ は `brevity penalty` と呼ばれ, 短い生成文程スコアが高くなってしまう問題を防ぐための項で短い文章であればあるほど小さくなり, ペナルティとなる."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28120d98",
   "metadata": {},
   "source": [
    "#### 具体例\n",
    "$\\mathscr{S}_\\mathrm{sys} = \\{ S_\\mathrm{sys} \\}, S_{\\mathrm{sys}}$ = `\"the the the the the the the\"`,  \n",
    "$S_{\\mathrm{ref}}$ = `\"The cat is on the mat\"`\n",
    "の時  \n",
    "$N = 4$ を考える.  \n",
    "$n = 1$ での適合率 $p_1$ は,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathrm{ngram} &= \\mathrm{[``the\", ``the\", ``the\", ``the\", ``the\", ``the\", ``the\"]} \\\\\n",
    "\\mathrm{count}(\\mathrm{ngram}) &= 7 \\\\\n",
    "\\mathrm{count\\_clip}(\\mathrm{ngram}, \\textrm{``The cat is on the mat\"}) &= \\min(2, 7) = 2\n",
    "\\end{align*}\n",
    "$$\n",
    "より, $p_1 = \\frac{2}{7}$ となる. $\\mathrm{BP} = 1$ より, $\\mathrm{BLEU}_1 = \\frac{2}{7}$ となる.   \n",
    "$2$-gram以上では一致するものが無いので, $p_i = 0 (i = 2, 3, 4)$ となり, $\\mathrm{BLEU}_i = 0$ となる.  \n",
    "よって $\\mathrm{BLEU} = \\frac{2}{7}$ となる."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad0ef50",
   "metadata": {},
   "source": [
    "### ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee17c01",
   "metadata": {},
   "source": [
    "ROUGE-$N$ は再現率を元にした指標で, 参照文章群 $\\mathscr{S}_\\mathrm{ref}$ に対する生成文 $S_{\\mathrm{sys}}$ の ROUGE-$N$ スコアは"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b31d75",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textrm{ROUGE-}N = \\frac{\n",
    "    \\displaystyle\n",
    "    \\sum_{S \\in \\mathscr{S}_{\\mathrm{ref}}}\n",
    "    \\sum_{\\mathrm{ngram} \\in \\mathrm{n\\_gram}(S)}\n",
    "    \\mathrm{count}_{\\mathrm{match}}(\\mathrm{ngram})\n",
    "}{\n",
    "    \\displaystyle\n",
    "    \\sum_{S \\in \\mathscr{S}_{\\mathrm{ref}}}\n",
    "    \\sum_{\\mathrm{ngram} \\in \\mathrm{n\\_gram}(S)}\n",
    "    \\mathrm{count}(\\mathrm{ngram})\n",
    "    \n",
    "} \\\\\n",
    "$$\n",
    "\n",
    "$\\mathrm{count}_{\\mathrm{match}}(\\mathrm{ngram})$ は $S_{\\mathrm{sys}}$ と $S_{\\mathrm{ref}}$ に共に現れる $N$-gramの個数の最大値を表す."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7272e7",
   "metadata": {},
   "source": [
    "#### 具体例\n",
    "$S_{\\mathrm{ref}}$ = `\"I am a cat\"`, $S_{\\mathrm{sys}}$ = `\"there is a cat on the mat\"` のとき,   \n",
    "ROUGE-$1$ は, $\\mathrm{count}(\\mathrm{ngram}) = 7$, $1$-gram の `\"a\"` と `\"cat\"` が $\\mathrm{n\\_gram}(S_{\\mathrm{sys}})$ にも含まれるので ROUGE-$1$ = $\\frac{2}{7}$ となる.  \n",
    "ROUGE-$2$ は, $\\mathrm{count}(\\mathrm{ngram}) = 6$, $2$-gram の `\"a cat\"` が $\\mathrm{n\\_gram}(S_{\\mathrm{sys}})$ にも含まれるので ROUGE-$2$ = $\\frac{1}{6}$ となる.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4541de1",
   "metadata": {},
   "source": [
    "### ROUGE-L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dcc232",
   "metadata": {},
   "source": [
    "ROUGE-Lは最長共通部分列(LCS)の長さを元にした指標である.\n",
    "\n",
    "$$\n",
    "\\textrm{ROUGE-L} = \\frac{(1 + \\beta^2) R_{\\mathrm{lcs}} P_{\\mathrm{lcs}}}{R_{\\mathrm{lcs}} + \\beta^2 P_{\\mathrm{lcs}}} \\\\\n",
    "\\begin{align*}\n",
    "\\mathrm{where} \\ \n",
    "P_\\mathrm{lcs} &= \\frac{\\mathrm{LCS}(S_\\mathrm{sys}, S_\\mathrm{ref})}{ |S_\\mathrm{ref}| } \\\\\n",
    "R_\\mathrm{lcs} &= \\frac{\\mathrm{LCS}(S_\\mathrm{sys}, S_\\mathrm{ref})}{ |S_\\mathrm{sys}| }\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99ed28",
   "metadata": {},
   "source": [
    "#### 具体例\n",
    "$\\beta = 1$, $S_{\\mathrm{ref}}$ = `\"I am a cat\"`, $S_{\\mathrm{sys}}$ = `\"there is a cat on the mat\"` のとき, $\\mathrm{LCS}(S_\\mathrm{sys}, S_\\mathrm{ref}) = 2$ (`\"a cat\"`) より,  \n",
    "$\\mathrm{R}_\\mathrm{lcs} = \\frac{2}{4}, \\mathrm{P}_\\mathrm{lcs} = \\frac{2}{7}$ よって,  \n",
    "$\\textrm{ROUGE-L} = \\frac{4}{11}$ となる."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a3606",
   "metadata": {},
   "source": [
    "### METEOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87de3b",
   "metadata": {},
   "source": [
    "METEORは [4] で提案された評価指標で, BLEU等に比べてより人間が評価した時の指標と相関するように設計された指標である. $1$-gramでの適合率を $P$, 再現率を $R$ とすると, $\\mathrm{METEOR}$ は以下のように計算できる."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f004a4c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textrm{METEOR} = \\textrm{Fmean} \\cdot (1 - \\textrm{Penalty}) \\\\\n",
    "\\begin{align*}\n",
    "\\mathrm{where} \\ \n",
    "\\mathrm{Fmean} &= \\frac{PR}{\\alpha P + (1 - \\alpha) R} \\\\\n",
    "\\mathrm{Penalty} &= \\gamma \\cdot \\left(\n",
    "    \\frac{\\mathrm{\\#chunks}}{\\mathrm{\\#unigrams\\_matched}}\n",
    "\\right)^\\beta\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c666e",
   "metadata": {},
   "source": [
    "$\\textrm{\\#unigrams\\_matched}$ は共通した単語数を表し, $\\textrm{\\#chunks}$ は部分列のかたまりの個数を表している."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d407f196",
   "metadata": {},
   "source": [
    "#### 具体例\n",
    "$\\alpha = 0.9, \\beta = 3, \\gamma = 0.5$ の時,\n",
    "$S_{\\mathrm{ref}}$ = `\"I am a cat\"`, $S_{\\mathrm{sys}}$ = `\"there is a cat on the mat\"` のとき,   \n",
    "$P = \\frac{2}{4}, R= \\frac{2}{7}$, $F_\\mathrm{mean} = \\frac{20}{67}$  \n",
    "$\\mathrm{\\#unigrams\\_matched} = 2$ (`\"a\"`, `\"cat\"`), $\\mathrm{\\#chunks} = 1$ (`\"a cat\"`) なので $\\mathrm{Penalty} = \\frac{1}{16}$.  \n",
    "よって, $\\mathrm{METEOR} = \\frac{75}{268}$ となる."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f757e3",
   "metadata": {},
   "source": [
    "### Recall@k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc21b59",
   "metadata": {},
   "source": [
    "[5] 等で用いられている情報検索の評価指標であり, 入力画像に対して上位 $k$ 件のキャプションを検索した際に正解のキャプションがいくつ含まれているかどうか割合を $\\mathrm{Recall@}k$ としている."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20c434",
   "metadata": {},
   "source": [
    "#### 具体例\n",
    "正解キャプションが全体で5つあり, Top-$5$ に正解キャプションが3つ含まれている場合の $\\mathrm{Recall@}5 = \\frac{3}{5}$ となる."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40361e62",
   "metadata": {},
   "source": [
    "## (2) 画像キャプションの最新の技術動向について\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed965b",
   "metadata": {},
   "source": [
    "2015年以降, 深層学習を用いた画像キャプション生成がより盛んになり, キャプション生成の精度をより高めようという潮流と, よりマルチモーダルに多様な課題を解決しようという課題自体の進化の潮流で発展していく.  \n",
    "\n",
    "### よりキャプションの精度を高めるための研究\n",
    "Attentionの他に精度向上に寄与したのが損失関数の改善である.  \n",
    "以前は, キャプションに対して交差エントロピーを損失関数としていたが, 画像からキャプションを生成するタスクとその逆のタスクに対して損失関数を設定して損失を最小化するというような一貫性損失を用いた手法が提案された.  \n",
    "\n",
    "例えば [7] では, 画像 $I$ と画像内の領域 $r$ からその領域のキャプション文章 $w$ を生成するタスク $G: I \\times r \\to w$ に対して損失関数 $C_\\mathrm{gen}$ を設定し, その逆に 画像 $I$ と質問 $q$ と領域の候補 $\\mathcal{R}$ から適切な領域 $\\hat{r}$ を選択する認識タスク $C: I \\times q \\times \\mathcal{R} \\to r$ に対する損失関数 $C_\\mathrm{com}$ を設定し, それらを組み合わせた一貫性損失 $L = L_\\mathrm{gen} + \\lambda L_\\mathrm{com}$ を最小化するように学習することでより精度の高いキャプションを生成することに成功している.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283bb6c",
   "metadata": {},
   "source": [
    "### キャプション生成の課題自体の進化\n",
    "また, キャプション生成課題自体の進化についても説明する.  \n",
    "従来の画像キャプション生成タスクは1枚の画像の全体に対し, 客観的な文章を英語で生成するタスクであったが, キャプションする対象はより多様になり, 前述した [7] では画像内の複数領域に対するキャプションを生成したり, 動画に対してのキャプション生成も行われている.  \n",
    "\n",
    "また, 英語以外の言語での画像キャプション生成についても検討されている. [8] では, 英語で事前学習済みの画像キャプション生成モデルを用意し, 入力部分に最も近い層以外を未学習の日本語生成キャプション生成モデルにして日本語のデータセットで学習した結果, 日本語のみのデータセットで1から学習させるよりも性能が改善したと報告している. この結果より, 言語間を跨ぐ画像キャプション生成も可能であると言っている.  \n",
    "\n",
    "また, 画像を用いたマルチモーダルな対話システムについても研究されていて, より高度なマルチモーダルタスクを想定したデータセットが存在する.  \n",
    "正解画像を見ている相手に対して, いくつかの質問をすることで画像を推定する対話のデータセットや, 目的地までの経路移動を自然言語により視覚的な目印となり得る情報と移動方向を指示したデータセットなどが構築されている."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d015c0b1",
   "metadata": {},
   "source": [
    "### 参考文献\n",
    "[1]\n",
    "⽶⾕ ⻯, et al. コンピュータビジョン : 広がる要素技術と応⽤… 共⽴出版, 2018.  \n",
    "[2] \n",
    "Papineni, K., Roukos, S., Ward, T., & Zhu, W.J. (2002). Bleu: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (pp. 311–318). Association for Computational Linguistics.  \n",
    "[3]\n",
    "Lin, C.Y. (2004). ROUGE: A Package for Automatic Evaluation of Summaries. In Text Summarization Branches Out (pp. 74–81). Association for Computational Linguistics.  \n",
    "[4]\n",
    "Banerjee, S., & Lavie, A. (2005). METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization (pp. 65–72).  \n",
    "[5]\n",
    "Hodosh, M., Young, P., & Hockenmaier, J. (2013). Framing image description as a ranking task: Data, models and evaluation metrics. Journal of Artificial Intelligence Research, 47, 853–899.  \n",
    "[6]\n",
    "牛久祥孝 (2019). 画像に関連した言語生成の取組み. 人工知能, 34(4), 483–491.  \n",
    "[7]\n",
    "Luo, R., & Shakhnarovich, G. (2017). Comprehension-guided referring expressions. arXiv:1701.03439 [cs].  \n",
    "[8]\n",
    "Miyazaki, T., & Shimizu, N. (2016). Cross-Lingual Image Caption Generation. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 1780–1790). Association for Computational Linguistics.  \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ea4080ffbbea1a535fa99c582455d0f78502373bf2d24d80b9626dd21aa0b5a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
